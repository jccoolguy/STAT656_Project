---
title: "Data Preprocessing"
author: "Jack"
date: "2025-02-19"
output: html_document
---

```{r load_packages}
require(tidyverse)
require(openxlsx)
require(caret)
source("helper_functions.R")
```

```{r read dataframe, cache = TRUE}
path_df = "Database/LoanStats3a.csv"
path_dict = "Database/LCDataDictionary.xlsx"
df = read.csv(path_df)
#sheets = getSheetNames(path_dict)
dictionary = read.xlsx(path_dict, sheet = "LoanStats")
```

```{r getting assigned columns}
df_jack = df |> 
  select(1:40)
```

```{r}
num_strings = c("(?i)number|amount|total|percent|months|range|income|received|
                balance")
factor_strings = c("(?i)indicates|status|category|month|grade|state|code")
string_strings = c("(?i)description|title")
#id_strings = c("(?i)id|url")
date_strings = c("(?i)date")
dictionary_w_types = dictionary |> 
  mutate(num = str_detect(Description,num_strings)) |> 
  mutate(factor = str_detect(Description, factor_strings)) |> 
  mutate(string = str_detect(Description, string_strings)) |> 
  mutate(date = str_detect(Description, date_strings))
```

```{r complicated combos}
complicated_types = dictionary_w_types |> 
  filter(LoanStatNew %in% colnames(df_jack)) |> 
  mutate(matches = num + factor + string + date) |> 
  filter(matches > 1)
```

```{r}
c_types = complicated_types |>
  mutate(action = c(rep("num", 7),rep("factor",1),rep("drop",1)))
```

```{r simple combos}
simple_types = dictionary_w_types |> 
  filter(LoanStatNew %in% colnames(df_jack)) |> 
  mutate(matches = num + factor + string + date) |> 
  filter(matches == 1)
```

```{r}
s_types = simple_types |> 
  mutate(action = case_when(num == TRUE ~ "num",
                            factor == TRUE ~ "factor",
                            string == TRUE ~ "string")) |> 
  mutate(action = ifelse(row_number() == 12, "num",action))
```

```{r last combos}
unknown_types = dictionary_w_types |> 
  filter(LoanStatNew %in% colnames(df_jack)) |> 
  mutate(matches = num + factor + string + date) |> 
  filter(matches == 0)
```

```{r}
u_types = unknown_types |> 
  mutate(action = c("num","drop","num","drop","drop"))
```

```{r}
types = rbind(s_types, c_types, u_types) |> 
  mutate(action = ifelse(LoanStatNew %in% c("earliest_cr_line","issue_d"),
                         "date",action))
```

Processing

```{r features}
num_features = types |>
  filter(action == "num") |> 
  select(LoanStatNew) |> 
  unlist(use.names = FALSE)
factor_features = types |> 
  filter(action == "factor") |> 
  select(LoanStatNew) |> 
  unlist(use.names = FALSE)
string_features = types |> 
  filter(action == "string") |> 
  select(LoanStatNew) |> 
  unlist(use.names = FALSE)
date_features = types |> 
  filter(action == "date") |> 
  select(LoanStatNew) |> 
  unlist(use.names = FALSE)
```

```{r}
data_num = df_jack |> 
  select(all_of(num_features)) |> 
  mutate_all(as.numeric)
```

```{r}
data_factor = df_jack |> 
  select(all_of(factor_features)) |> 
  mutate_all(as.factor)
```

```{r}
data_string = df_jack |> 
  select(all_of(string_features))
```

```{r}
data_date = df_jack |> 
  select(all_of(date_features))
```

Preprocessing

```{r}
data_pre_processed = cbind(data_num,data_factor,data_string,data_date)
dim(data_pre_processed)
```

Using near-zero-preprocessing

```{r}
data_processed = data_pre_processed |> preProcess(method = 'nzv') |> 
  predict(newdata = data_pre_processed)
dim(data_processed)
head(data_processed)
```

We removed 6 columns this way.

Missing values:

```{r}
n = dim(data_processed)[1]
missing_values_by_feature = sapply(data_processed, function(x) 100*sum(is.na(x))/n)
missing_values_by_feature[missing_values_by_feature > 50]
```

Mostly within reason except for these two, lets see how to handle.

Questions to ask:

How do we deal with description data, it could help us label the "other" categories in the purpose column. Many use other and still are going for debt consolidation.

With date data, its not consistent but seems to have a pattern. Should we attempt to create a numeric value, like months since... or not use at all.

How should we work through these columns which have a high amount of missings?

How should we attempt to narrow down features? Correlation filtering?

Should we exclude features like interest rate which already give us an idea of the risk of a loan?
